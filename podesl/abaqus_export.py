from __future__ import annotations

from dataclasses import dataclass
import subprocess
from pathlib import Path
from typing import Any, Dict, Iterable, List, Mapping, Optional, Sequence, Tuple

import numpy as np

from .parser import parse
from .runtime import eval_expr

_DOF_NUMBERS = {
    "ux": 1,
    "uy": 2,
    "uz": 3,
    "rx": 4,
    "ry": 5,
    "rz": 6,
}

_DOF_ALIASES = {
    "both": ("ux", "uy"),
    "xy": ("ux", "uy"),
    "xz": ("ux", "uz"),
    "yz": ("uy", "uz"),
    "xyz": ("ux", "uy", "uz"),
    "all": tuple(_DOF_NUMBERS.keys()),
}

_SUPPORTS_DOF_ORDER = ("ux", "uy", "rz")
_LOAD_DOF_ORDER = ("ux", "uy", "uz", "rx", "ry", "rz")


@dataclass
class AbaqusExportResult:
    path: Path
    node_count: int
    element_count: int
    job_name: str
    metadata: Dict[str, Any]


def build_environment(ast: Dict[str, Any]) -> Dict[str, Any]:
    """
    Evaluate GIVEN/SOLVE/EQUATIONS blocks to reconstruct the env dict without executing the full solver.
    """

    env: Dict[str, Any] = {}
    for block in ast.get("blocks", []):
        btype = block.get("type")
        if btype not in {"given", "solve", "equations"}:
            continue
        for stmt in block.get("stmts", []):
            kind = stmt.get("kind")
            if kind == "assign":
                name = stmt.get("name")
                expr = stmt.get("value")
                if not name or expr is None:
                    continue
                env[name] = eval_expr(expr, env)
            elif btype == "equations" and kind == "command":
                if stmt.get("name") != "eq":
                    continue
                args = stmt.get("args") or []
                if not args:
                    continue
                env.setdefault("equations", []).append(eval_expr(args[0], env))
    return env


def build_abaqus_input(
    problem: Dict[str, Any],
    env: Dict[str, Any],
    metadata: Optional[Dict[str, Any]] = None,
) -> str:
    """
    Return the Abaqus .inp contents for the provided problem/environment.
    """

    metadata = dict(metadata or {})
    nodes = _coerce_nodes(env.get("nodes"))
    elems = _coerce_elements(env.get("elems"))
    if nodes is None or elems is None:
        raise ValueError("Abaqus export requires 'nodes' and 'elems' entries.")
    node_labels = np.arange(1, nodes.shape[0] + 1)
    elem_labels = np.arange(1, elems.shape[0] + 1)
    elem_conn = elems + 1  # convert from 0-based indexing

    element_type = _deduce_element_type(problem.get("code", ""))
    material_name = metadata.get("material_name") or env.get("material_name") or "MAT1"
    section_name = metadata.get("section_name") or "EALL"
    youngs = float(metadata.get("E") or env.get("E") or env.get("youngs", 0.0))
    if not youngs:
        raise ValueError("Abaqus export needs an 'E' (Young's modulus) value.")
    poisson = float(metadata.get("nu") or env.get("nu", 0.3))
    density = metadata.get("density") or env.get("rho") or env.get("density")
    area = float(metadata.get("A") or env.get("A") or env.get("area", 1.0))
    step_name = metadata.get("step_name") or "StaticStep"
    job_name = _pick_job_name(problem, metadata)

    bc_rows = _collect_boundary_conditions(env)
    load_rows = _collect_point_loads(env)

    fmt = lambda value: f"{float(value):.9g}"

    lines: List[str] = []
    lines.append("*Heading")
    lines.append(f"** Generated by PoDESL for {problem.get('title', 'PoDESL Problem')}")
    lines.append("*Preprint, echo=NO, model=NO, history=NO, contact=NO")
    lines.append("*Node")
    for label, xyz in zip(node_labels, nodes):
        lines.append(f"{label}, {fmt(xyz[0])}, {fmt(xyz[1])}, {fmt(xyz[2])}")

    lines.append(f"*Element, type={element_type}, elset={section_name}")
    for eid, conn in zip(elem_labels, elem_conn):
        nodes_str = ", ".join(str(int(idx)) for idx in conn)
        lines.append(f"{eid}, {nodes_str}")

    lines.append(f"*Material, name={material_name}")
    lines.append("*Elastic")
    lines.append(f"{fmt(youngs)}, {fmt(poisson)}")
    if density:
        lines.append("*Density")
        lines.append(fmt(density))

    lines.append(f"*Solid Section, elset={section_name}, material={material_name}")
    lines.append(fmt(area))

    if bc_rows:
        lines.append("*Boundary")
        for node, dof, value in bc_rows:
            lines.append(f"{node}, {dof}, {dof}, {fmt(value)}")

    lines.append(f"*Step, name={step_name}, nlgeom=NO")
    lines.append("*Static")
    lines.append("1., 1., 1e-05, 1.")

    if load_rows:
        lines.append("*Cload")
        for node, dof, value in load_rows:
            lines.append(f"{node}, {dof}, {fmt(value)}")

    lines.append("*Output, field")
    lines.append("*Node Output")
    lines.append("U")
    lines.append("*Element Output")
    lines.append("S")
    lines.append("*End Step")

    return "\n".join(lines)


def export_abaqus_input(
    source: str,
    filename: str,
    output_path: Path,
    metadata: Optional[Dict[str, Any]] = None,
) -> AbaqusExportResult:
    """
    Build the Abaqus .inp file directly from source text.
    """

    ast = parse(source, filename=filename)
    env = build_environment(ast)
    job_name = _pick_job_name(ast["problem"], metadata)
    text = build_abaqus_input(ast["problem"], env, metadata)
    output_path = Path(output_path).resolve()
    output_path.parent.mkdir(parents=True, exist_ok=True)
    output_path.write_text(text, encoding="utf-8")
    info = AbaqusExportResult(
        path=output_path,
        node_count=len(env.get("nodes") or []),
        element_count=len(env.get("elems") or []),
        job_name=job_name,
        metadata=dict(metadata or {}, job_name=job_name),
    )
    return info


def run_abaqus_job(
    inp_path: Path,
    abaqus_exec: str = "abaqus",
    job_name: Optional[str] = None,
) -> subprocess.CompletedProcess:
    """
    Invoke the Abaqus CLI on the generated input deck.
    """

    inp_path = Path(inp_path).resolve()
    if not inp_path.is_file():
        raise FileNotFoundError(inp_path)
    job = job_name or inp_path.stem
    cmd = [abaqus_exec, f"job={job}", f"input={inp_path.name}"]
    return subprocess.run(cmd, cwd=str(inp_path.parent), check=True)


def _coerce_nodes(raw: Any) -> Optional[np.ndarray]:
    if raw is None:
        return None
    arr = np.asarray(raw, dtype=float)
    if arr.ndim == 1:
        raise ValueError("nodes must be a nested list/array of coordinates.")
    if arr.ndim != 2:
        raise ValueError("nodes must be a 2D array.")
    if arr.shape[1] == 1:
        arr = np.hstack([arr, np.zeros((arr.shape[0], 2))])
    elif arr.shape[1] == 2:
        arr = np.hstack([arr, np.zeros((arr.shape[0], 1))])
    elif arr.shape[1] > 3:
        arr = arr[:, :3]
    return arr


def _coerce_elements(raw: Any) -> Optional[np.ndarray]:
    if raw is None:
        return None
    arr = np.asarray(raw, dtype=int)
    if arr.ndim == 1:
        if arr.size % 2 != 0:
            raise ValueError("elems 1D array must contain pairs of node indices.")
        arr = arr.reshape(-1, 2)
    if arr.ndim != 2 or arr.shape[1] < 2:
        raise ValueError("elems must be an (n,2) array or list.")
    return arr[:, :2]


def _deduce_element_type(problem_code: str) -> str:
    code = (problem_code or "").upper()
    if "TRUSS3D" in code:
        return "T3D2"
    if "TRUSS2D" in code:
        return "T2D2"
    if "FRAME3D" in code:
        return "B31"
    if "FRAME2D" in code:
        return "B21"
    return "T3D2"


def _collect_boundary_conditions(env: Dict[str, Any]) -> List[Tuple[int, int, float]]:
    rows: List[Tuple[int, int, float]] = []
    sources = [
        env.get("fix"),
        env.get("bcs"),
        env.get("dirichlet"),
        env.get("constraints"),
    ]
    supports = env.get("supports")
    if supports:
        for entry in supports:
            if not isinstance(entry, Sequence) or len(entry) < 2:
                continue
            node = int(entry[0])
            flags = list(entry[1:1 + len(_SUPPORTS_DOF_ORDER)])
            for idx, flag in enumerate(flags):
                if float(flag):
                    dof_name = _SUPPORTS_DOF_ORDER[idx]
                    rows.append((node + 1, _DOF_NUMBERS[dof_name], 0.0))
    for src in sources:
        if not src:
            continue
        for node, dof, value in _iter_bc_entries(src):
            rows.append((node + 1, _DOF_NUMBERS[dof], value))
    rows.sort()
    return rows


def _iter_bc_entries(entries: Iterable) -> Iterable[Tuple[int, str, float]]:
    for item in entries:
        node: Optional[int] = None
        dof: Optional[str] = None
        value = 0.0
        if isinstance(item, Mapping):
            node = int(item.get("node"))
            dof = str(item.get("dof", "")).lower()
            value = float(item.get("value", 0.0))
        elif isinstance(item, Sequence) and len(item) >= 2:
            node = int(item[0])
            dof = str(item[1]).lower()
            if len(item) >= 3:
                value = float(item[2])
        if node is None or dof is None:
            continue
        expanded = _DOF_ALIASES.get(dof, (dof,))
        for actual in expanded:
            if actual not in _DOF_NUMBERS:
                continue
            yield node, actual, value


def _collect_point_loads(env: Dict[str, Any]) -> List[Tuple[int, int, float]]:
    rows: List[Tuple[int, int, float]] = []
    for key in ("loads", "point_loads", "forces"):
        entries = env.get(key)
        if not entries:
            continue
        for node, vector in _iter_load_entries(entries):
            for idx, value in enumerate(vector):
                if abs(value) < 1e-12:
                    continue
                dof = idx + 1
                rows.append((node + 1, dof, value))
    rows.sort()
    return rows


def _iter_load_entries(entries: Iterable) -> Iterable[Tuple[int, List[float]]]:
    for item in entries:
        node: Optional[int] = None
        forces = [0.0] * len(_LOAD_DOF_ORDER)
        if isinstance(item, Mapping):
            node = int(item.get("node"))
            dof = str(item.get("dof", "")).lower()
            value = float(item.get("value", 0.0))
            if dof in _DOF_NUMBERS:
                idx = _LOAD_DOF_ORDER.index(dof)
                forces[idx] = value
        elif isinstance(item, Sequence) and len(item) >= 2:
            node = int(item[0])
            numeric = [float(val) for val in item[1:1 + len(_LOAD_DOF_ORDER)]]
            for idx, val in enumerate(numeric):
                forces[idx] = val
        if node is None:
            continue
        yield node, forces


def _pick_job_name(problem: Dict[str, Any], metadata: Optional[Dict[str, Any]]) -> str:
    candidate = None
    if metadata:
        candidate = metadata.get("job_name")
    if candidate:
        return candidate
    title = (problem.get("title") or "podesl_model").strip()
    sanitized = "".join(ch if ch.isalnum() or ch in ("-", "_") else "_" for ch in title)
    return sanitized or "podesl_model"
